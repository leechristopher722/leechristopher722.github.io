[{"content":"","date":null,"permalink":"/tags/backend-development/","section":"Tags","summary":"","title":"Backend Development"},{"content":" My Learning Journey ","date":null,"permalink":"/blog/","section":"Blog","summary":" My Learning Journey ","title":"Blog"},{"content":" Designing and Developing Tomorrow\u0026rsquo;s Solutions Welcome to my portfolio! Discover my projects, blog, and experiences, and feel free to reach out. I\u0026rsquo;m always excited to collaborate on new challenges and opportunities!\n","date":null,"permalink":"/","section":"Christopher Lee","summary":"Designing and Developing Tomorrow\u0026rsquo;s Solutions Welcome to my portfolio!","title":"Christopher Lee"},{"content":"What is Cloud Computing? On-Premise\nLess scalability (less flexibility) Server Storage (have to maintain and power it) Less Data Security Data Loss (data recovery can be hard) Maintenance have to be done by the company itself Less collaboration Cloud\nMore scalability (more flexibility) Server Storage (have to maintain and power it) Better Data Security Data Loss (data recovery measures are there) Maintenance More collaboration (easier to share data in diff locations) About Cloud Delivery of on demand computing services on the internet Pay-as-you-Go (pay more, scale up / pay less, scale down) Cost efficient Deployment Model Public Cloud Like a bus Lower cost (pay only for resources used) Owned by Cloud Providers Private Cloud Like owning a car Managed by single organization or third party Pay large amount up front (owned by the company) Hybrid Cloud Using both Like in Federal Agencies (store personal data, share nonsensitive data on public cloud) Service Model IaaS Infrastructure Access to basic computing infrastructure Commonly used by IT Administrators Storage or VMs, Networking, Servers Pay for What You Use PaaS Platforms Platform and runtime environments provided for Dev, Testing, Managing Applications Commonly Used By Software Developers Don\u0026rsquo;t have to acquire, manage, maintain related architecture Only have to handle App and Data SaaS Software Involves hosting and managing software applications Not owning any IT equipment Commonly Used by End Customers Popular Services AWS Services over the Internet IaaS is their main Subscriptions are pay what you use Azure Google Cloud Platform Lifecycle of Cloud Computing Solution Understand the requirements of the business (Define purpose) Choose a compute service that will provide the right support where you resize the compute capacity in the cloud to run application programs (Define the Hardware ex. EC2, Lambda, Elastic Container Service) Define Storage - Choose storage service for backup and archive data (S3, EFS, Glacier) Define Network - securely deliver data, videos, applications, etc (VPC, Route 53, Direct Connect) Define Security - user Auth, etc. (IAM, KMS, Cognito) Define Management Processes and Tools (CloudWatch, Auto scaling, CloudFormation) Testing Process - CodeStar, CodeBuild, CodePipeline (build, test, deploy code quickly) Analytics - Athena, EMR, CloudSearch Containers Docker, Cloud Foundary, Kubernetes, etc. ","date":"20 March 2024","permalink":"/blog/cloud/","section":"Blog","summary":"What is Cloud Computing?","title":"Cloud"},{"content":"","date":null,"permalink":"/tags/cloud-computing/","section":"Tags","summary":"","title":"Cloud Computing"},{"content":"Write about restful api here.\nAPI: Application Programming Interface. Piece of software that can be used by another piece of software, in order to allow applications to talk to each other.\nREST:\nSeparate API into logical resources users projects bugs teams Expose structured, resource-based urls *//www.myproject.com/addNewProject (not good) *//www.myproject.com/projects/8(Project ID) (use HTTP Method such as \u0026lsquo;get\u0026rsquo;) Use HTTP methods Create: Post Read: Get Update: Put / Patch (for patch, only need part of object) Delete: Delete Send data as JSON Be stateless All state is handled on the client Server should not have to remember previous requests Only use app.js for express related configs \u0026amp; more For env variables, deal with it in server.js\nEnvironment Variables\nDev Environment NODE_ENV = development Prod Environment NODE_ENV = production MongoDB\nNoSQL database Collections (tables) Documents (rows) Scalable \u0026amp; Flexible Mongoose\nObject Data Modeling(ODM) library for MongoDB and Node.js, higher level abstraction rqpid and simple development of mongoDB database interactions schemas, easy data validations, simple query api, middleware etc. schema: where we model data, describing structure, default vals, and validation Mongoose model: wrapper for the schema, pproviding an interface to the database for CRUD operations MVC Separate Business Logic \u0026amp; Application Logic\nApplication Logic (Controller) Only concerned with application\u0026rsquo;s implementation managing req and res more of technical aspects bridge between model and view Business Logic (Model) Code tath actualy solves the business problem Directly related to business rules EX Creating new tours in database Check if user pw is correct Validating user input data Ensuring only users who bought a tour can review it Fat Models \u0026amp; Thin Controllers: offload as much logic as possible onto the model, and keep controllers as simple as possible Model\nApplications data, Business logic Controller\nHandle application requests, interact with models, send back responses to client View\nGUI, server-side rendered wbesites Alias\nCreating middleware for popular routers/requests Aggregation Pipeline\nFor grouping, sorting, filtering data to get statistics that are useful for ex business needs Mongoose Middleware:\nDocument Middleware: before or after saving documents Query Middleware: Aggregation Middleware: Model Middleware Data Sanitization \u0026amp; Validation Setting models for each data types Errors in Express Operational error Problems that we can predict will happen at some point Invalid user input, failed to connect to server, request timeout, invalid path accessed, etc. -\u0026gt; Create a global express handling middleware so that all operational errors end up there.\nProgramming error Bugs in code User Authentication \u0026amp; Authorization bcrypt for password hashing =\u0026gt; Argon2 is the newest algorithm among these and is currently considered to be the strongest password hashing algorithm available. It is designed to be memory-hard, meaning that it requires a lot of memory to compute. This makes it difficult for attackers to use specialized hardware like GPUs and ASICs to crack passwords. Argon2 has several parameters that need to be kept in mind when using it, such as the amount of memory to use and the number of iterations to perform. Bcrypt is an older algorithm but is still widely used and considered to be secure. It is designed to be computationally expensive, meaning that it requires a lot of processing power to compute. Bcrypt has a cost parameter that determines the number of iterations to perform, and it also has a work factor that determines the amount of memory to use.\nScrypt is similar to bcrypt in that it is also designed to be computationally expensive. However, it is also designed to be memory-hard, like Argon2. Scrypt has several parameters that need to be kept in mind, such as the amount of memory to use and the number of iterations to perform.\nPBKDF2 is a key derivation function that is designed to be computationally expensive. It is often used in conjunction with other algorithms, such as SHA-256 or SHA-512, to create a stronger password hashing function. PBKDF2 has a number of parameters, such as the number of iterations to perform and the length of the derived key.\nWhen choosing which algorithm to use, it\u0026rsquo;s important to consider the specific requirements of your use case. Factors such as the number of users, the computing resources available, and the security requirements should all be taken into account. In general, newer algorithms like Argon2 are considered to be stronger than older ones like bcrypt and PBKDF2, but they may require more memory or processing power to compute. It\u0026rsquo;s also important to keep in mind that password hashing is just one aspect of password security, and other measures like password policies and multi-factor authentication should also be used to improve security.\nJSON WEB TOKEN WRITE HOW IT WORKS\nUser AUTH IS SERIOUS AND IMPORTANT: DO IT RIGHT\nSent email for resetting password\nSecurity Practices Copmromised Database Encrypt passwords with salt and hash (argon2) Encrypt password reset tokens (sha256) Brute force attacks Make login requests be slow (argon2) Implement rate limiting (express-rate-limit) Implement maximum login attempts (not implemented) Cross-site scripting(XSS) attacks Store JWT in HTTP only cookies Sanitize user input data Set special HTTP headers (helmet package) Denial-of-Service (DOS) attack Implement rate limiting (express-rate-limit) Limit body payload (in body-parser) Avoid evil regular expressions NoSQL Query Injection Use mongoose for MongoDB (schemaTypes) Sanitize user input data Other practices Always use HTTPS Create random password reset token with expiry dates Deny access to JWT after password change Don\u0026rsquo;t commit sensitive config data to Git Don\u0026rsquo;t send error details to clients Prevent Cross-Site Request Forgery (csurf package) Require re-authentication before a high-value action Implement a blacklist of untrusted JWT Confirm user email address after first creating account Keep user logged in with refresh tokens Implement two-factor authentication Prevent parameter pollution causing Uncaught Exceptions Data Modeling Different types of relationships between data\n1:1 1:Many 1:Few 1:Many 1:Ton Many:Many Referencing/normalization vs Embedding/denormalization\nReferenced Pro: Easier to query each document on its own Con: need 2 queries to get data from referenced document Embedded Pro: can get all the information in one query Con: impossible to query embedded document on its own Embedding or referencing decisions\nRelationship type Data access patterns Data closeness Different types of referencing\nChild referencing Parent referencing (Best One) Two-way referencing FACTORY FUNCTION\nWorks bc of JAVASCRIPT CLOSURES: Inner function gets access to vars of outer functions even after it is returned USE INDEXES TO IMPROVE DB READ PERFORMANCE: Consider read-write pattern, compare query of using exact field with cost of using index\nIt takes memory to use indexes. Only use on low Write-Read ratio documents (More reads than writes) TODO::Implement caching to prevent multiple requests of same data. https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Client-side_web_APIs/Client-side_storage Cookies vs Web Storage API vs IndexedDB For better performance and/or larger datasets, IndexedDB is better However, only used for simple use cases Handlebars SUCK Cannot directly access res.locals, but pug can Does not have extends, but only partials TO provide current project ID into JS Frontend Code, create a hidden field in HTML/Pug with req.body.project._id included TODO: Instead of deleting tickets \u0026amp; projects, mark them as inactive and simply don\u0026rsquo;t display it to user. Implemented Client-Side Rendering with frontend JS for comments on Tickets to reduce initial loading time and inefficient data retrievals To Learn\nPromise Feedback Loop function() {} vs () =\u0026gt; {} Static Method vs Review Method Choices Made MongoDB choice: mySQL, noSQL, postgreSQL (child vs parent vs 2 way refenrencing vs embedding) How I applied MVC Security measures done (pw on DB, argon2, and more) Performance improvements Which templating engines to use (Pug, handlebars, ejs) Which frontend framework should be used? Created a middleware that stores three recently viewed projects in cookie. ","date":"20 March 2024","permalink":"/blog/api/","section":"Blog","summary":"Write about restful api here.","title":"RESTful API"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"A project management platform designed to streamline how development teams work together by bringing task tracking, team communication, and project analytics into one unified workspace.\nThe Problem Development teams often juggle multiple disconnected tools—one for messaging, another for task tracking, and yet another for metrics. This fragmentation creates information gaps and makes it harder to maintain project visibility. Atelier addresses this by providing a single platform where teams can manage their entire workflow.\nKey Features 🔐 Authentication \u0026amp; Access Control\nArgon2 password hashing with JWT token-based sessions. Role-based permissions system (Admin, Project Manager, Developer, Team Member) controls access to project resources. Automated email notifications for password resets and task assignments.\n📊 Real-Time Collaboration\nShared Kanban boards with instant updates via WebSocket connections—drag a task and everyone sees it move immediately. Integrated chat keeps discussions in context with the relevant tasks. Visual analytics track sprint progress and identify bottlenecks.\n⚡ Technical Architecture\nNode.js/Express.js backend following MVC patterns with RESTful APIs. MongoDB for flexible document storage using Atlas for cloud hosting. Optimized database queries with proper indexing and efficient real-time event handling through Socket.io.\nTechnical Implementation The tech stack was chosen for practical reasons: Node.js handles concurrent connections well (crucial for real-time features), MongoDB allows schema flexibility during rapid development, and JWT authentication keeps the system stateless and scalable.\nEach API endpoint validates permissions through custom middleware. When someone updates a Kanban board, WebSocket events broadcast minimal data updates rather than full refreshes, keeping the system responsive even with multiple concurrent users.\nChallenges \u0026amp; Solutions Challenge: Synchronizing multiple clients without overwhelming the server\nSolution: Implemented event throttling and delta updates—sending only changed data instead of full state refreshes\nChallenge: Managing complex permission logic across different roles\nSolution: Centralized authorization middleware that validates permissions before any database operation\nCurrent Status Working Features:\nUser registration/login with secure authentication Project creation and team member management Drag-and-drop Kanban boards with real-time updates Basic chat system within project context Role-based access control across all features In Development:\nEnhanced analytics dashboard with actionable metrics Performance optimization for larger teams Mobile responsive UI improvements This ongoing project demonstrates practical application of full-stack development concepts while solving real team collaboration challenges.\n","date":"14 March 2024","permalink":"/projects/atelier/","section":"Projects","summary":"A project management platform designed to streamline how development teams work together by bringing task tracking, team communication, and project analytics into one unified workspace.","title":"Atelier"},{"content":"","date":null,"permalink":"/tags/machine-learning/","section":"Tags","summary":"","title":"Machine Learning"},{"content":" From ideas to reality ","date":null,"permalink":"/projects/","section":"Projects","summary":" From ideas to reality ","title":"Projects"},{"content":"The field of software development is witnessing a paradigm shift with the introduction of Devin, an AI tool claiming the title of the world\u0026rsquo;s first \u0026ldquo;AI software engineer.\u0026rdquo; This blog post delves into Devin\u0026rsquo;s technical underpinnings, analyzes its potential impact, and explores how it stands out from existing AI development tools.\nBeyond Code Completion: Unveiling Devin\u0026rsquo;s Technical Core Devin surpasses the capabilities of typical code-completion AI. It is believed to leverage a sophisticated blend of algorithms, including:\nNatural Language Processing (NLP): This empowers Devin to comprehend high-level instructions provided in natural language and translate them into specific coding tasks. Machine Learning (ML): Devin utilizes ML models trained on vast code repositories to grasp coding patterns, identify best practices, and detect potential bugs. Deep Learning (DL): While the specifics remain undisclosed, Devin likely employs DL algorithms to analyze code structure and functionality, enabling it to tackle complex tasks like code generation, debugging, and even deployment. Performance Evaluation: A Quest for Concrete Data A critical aspect of Devin\u0026rsquo;s development is its real-world performance. However, concrete benchmarks are currently limited. Cognition, Devin\u0026rsquo;s creator, asserts its ability to:\nGenerate entire applications based on a single prompt. Successfully complete real-world freelance projects on platforms like Upwork. Identify and rectify bugs within existing codebases. Independent testing and user evaluations are still in their infancy. It\u0026rsquo;s essential to acknowledge that Devin is likely under active development, and its true capabilities will likely unfold over time.\nA Step Ahead: How Devin Differs from Existing Tools While AI development tools like Github Copilot and ChatGPT have revolutionized code completion and assisted development, Devin offers a distinct advantage: end-to-end project management.\nHere\u0026rsquo;s how Devin breaks new ground:\nFull Development Lifecycle Management: Unlike assistants that focus on code snippets, Devin tackles the entire development lifecycle, from translating high-level ideas into code to debugging and deployment. Independent Problem-Solving: Devin reportedly possesses impressive planning abilities. It can anticipate potential challenges and structure the development process accordingly, minimizing human intervention. Constant Learning: Devin is said to continuously learn and improve from its experiences. This ongoing development cycle allows it to stay up-to-date with programming best practices and adapt to new technologies. Collaboration, Not Competition: Reshaping the Programmer-AI Dynamic While Devin\u0026rsquo;s code generation and project management skills are impressive, it\u0026rsquo;s crucial to view it as a collaborative tool, not a competitor. Here\u0026rsquo;s how Devin can truly empower programmers:\nEnhanced Efficiency: Repetitive coding tasks can be delegated to Devin, allowing programmers to focus on strategic planning and creative problem-solving. Error Reduction: Devin\u0026rsquo;s bug-detection capabilities can significantly improve code quality and expedite debugging processes. Exploration of New Technologies: Devin\u0026rsquo;s continuous learning can aid programmers in staying ahead of the curve by facilitating the exploration and integration of new technologies into their projects. The Future: Embracing an AI-Powered Development Landscape Devin\u0026rsquo;s arrival signifies that AI is not here to replace programmers, but rather to augment their capabilities. By embracing AI-powered tools like Devin, we can usher in a future of software development characterized by greater efficiency and groundbreaking innovation.\nThis is merely the beginning. As Devin and similar AI tools evolve, the way we approach software development will undoubtedly transform. It\u0026rsquo;s important to remain curious, experiment with these new tools, and prepare to co-create the future alongside our AI teammates.\n","date":"14 March 2024","permalink":"/blog/devin/","section":"Blog","summary":"The field of software development is witnessing a paradigm shift with the introduction of Devin, an AI tool claiming the title of the world\u0026rsquo;s first \u0026ldquo;AI software engineer.","title":"Thoughts on Devin: AI Software Engineer"},{"content":"In the realm of web development, crafting an online portfolio can often feel like a daunting task. As developers, we aim to showcase our skills and projects in an efficient, visually appealing manner. However, the process can become overwhelming without the right tools at our disposal. This is where Hugo and GitHub Pages come into play, offering a seamless solution for building and hosting dynamic portfolios. Let\u0026rsquo;s delve deeper into why this combination is a game-changer for developers.\nWhat is Hugo?\nHugo is a static site generator designed to simplify website development. Unlike traditional content management systems (CMS), such as WordPress or Drupal, Hugo generates static HTML files that can be served directly to the user\u0026rsquo;s browser. This means there\u0026rsquo;s no need for complex databases or server-side processing, resulting in a leaner, more efficient website.\nWhy is Hugo Fast?\nHugo\u0026rsquo;s speed is unparalleled, thanks to its architecture. It is built with Go, a programming language known for its speed and efficiency. Additionally, Hugo employs a clever caching mechanism that allows it to regenerate only the necessary files when changes are made, drastically reducing build times.\nIntroducing GitHub Pages:\nGitHub Pages is a static site hosting service offered by GitHub. It allows users to host their websites directly from their GitHub repositories. With GitHub Pages, developers can easily deploy their Hugo-generated sites with just a few clicks, taking advantage of GitHub\u0026rsquo;s robust infrastructure and version control capabilities.\nStrengths of Hugo and GitHub Pages:\nSimplicity: Both Hugo and GitHub Pages prioritize simplicity, making them accessible to developers of all skill levels. Hugo\u0026rsquo;s intuitive templating system and GitHub Pages\u0026rsquo; seamless deployment process streamline the entire development workflow. Customization: Despite their simplicity, Hugo and GitHub Pages offer ample opportunities for customization. Hugo provides a wide range of themes and customization options, allowing developers to tailor their portfolios to their unique style and preferences. GitHub Pages, on the other hand, supports custom domains and SSL certificates, enabling developers to create a professional online presence. Performance: The combination of Hugo and GitHub Pages results in lightning-fast websites. Since Hugo generates static HTML files, there\u0026rsquo;s no need for server-side processing, leading to near-instantaneous page loads. Additionally, GitHub Pages\u0026rsquo; global CDN ensures that content is delivered quickly to users around the world. Comparing Static Website Building Tools:\nWhile Hugo is undoubtedly a powerful static site generator, it\u0026rsquo;s essential to explore other options to determine the best fit for your project. Some popular alternatives include Jekyll, Gatsby, and Next.js. Each tool has its strengths and weaknesses, depending on factors such as performance requirements, ease of use, and community support.\nJekyll, for example, is well-suited for simple websites and blogs, thanks to its seamless integration with GitHub Pages. Gatsby, on the other hand, is ideal for more complex projects that require dynamic data fetching and server-side rendering. Next.js shines in the realm of React-based applications, offering advanced features like incremental static regeneration and hybrid rendering.\nIn conclusion, building an online portfolio doesn\u0026rsquo;t have to be a daunting task. With the powerful combination of Hugo and GitHub Pages, developers can create sleek, high-performance websites with ease. Whether you\u0026rsquo;re a seasoned developer or just starting, Hugo and GitHub Pages provide the perfect platform to showcase your skills and projects to the world.\nVisit the Hugo website!\n","date":"13 March 2024","permalink":"/blog/hugo/","section":"Blog","summary":"In the realm of web development, crafting an online portfolio can often feel like a daunting task.","title":"Building Static Website with HUGO"},{"content":"","date":null,"permalink":"/tags/hugo/","section":"Tags","summary":"","title":"Hugo"},{"content":"","date":null,"permalink":"/tags/cybersecurity/","section":"Tags","summary":"","title":"CyberSecurity"},{"content":"","date":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git"},{"content":"Introduction The vast landscape of software development is governed by one tool: Git. It\u0026rsquo;s the backbone of collaboration, enabling developers to work seamlessly together, track changes efficiently, and maintain a coherent history of their projects. However, like many budding developers, my journey into understanding Git was initially daunting and filled with uncertainty. Yet, as I delved deeper into its intricacies, I discovered its immense value and transformed my workflow.\nUnderstanding the Basics My foray into Git began with a simple desire—to streamline my coding projects and collaborate more effectively with my peers. As a novice developer, the prospect of learning a new tool seemed daunting. Git\u0026rsquo;s command-line interface appeared cryptic, and the plethora of commands felt overwhelming. However, armed with determination and a willingness to learn, I embarked on my journey.\nMy initial steps involved grasping the fundamental concepts of Git. Understanding terms like repositories, commits, branches, and merges laid the groundwork for my comprehension. I devoured online tutorials, perused documentation, and sought guidance from experienced developers. Slowly but surely, the fog began to lift, and I started to appreciate Git\u0026rsquo;s elegance.\nExploring Branches One of the pivotal moments in my Git journey was comprehending the concept of branches. Branching allowed me to diverge from the main codebase, experiment with new features, and isolate changes without disrupting the main project. It was akin to creating alternate realities where I could test ideas freely, knowing that I could always revert if needed. This newfound freedom unleashed my creativity and empowered me to explore different avenues in my projects.\nVisual representation of branching in Git\nAdvanced Functionalitie As I grew more proficient, I ventured into more advanced Git functionalities. Rebasing, squashing commits, and resolving merge conflicts were once intimidating concepts that now became integral parts of my workflow. Git became not just a version control system but a powerful toolkit that enabled me to manage my projects with finesse.\n# Example of rebasing in Git git checkout feature-branch git rebase main Overcoming Challenges However, like any journey of learning, I encountered roadblocks along the way. Git\u0026rsquo;s unforgiving nature meant that a single misstep could wreak havoc on my project. Accidentally deleting files, botching merges, or losing track of changes were all too familiar pitfalls. Yet, with each mistake, I gleaned valuable lessons and honed my skills further.\nCollaborative Workflows Moreover, Git\u0026rsquo;s collaborative nature became increasingly apparent as I worked on group projects. Branches transformed into collaborative spaces where team members could contribute code, review each other\u0026rsquo;s work, and seamlessly integrate changes. Pull requests became the cornerstone of our workflow, facilitating code reviews and ensuring the quality of our codebase.\nVisual representation of a collaborative Git workflow\nGit in the Industry Perhaps the most profound realization during my Git journey was its ubiquity within the software development industry. Virtually every tech company, from startups to tech giants, relies on Git for version control. Mastery of Git not only enhanced my individual capabilities but also opened doors to collaboration and employment opportunities within the industry.\nConclusion In hindsight, my journey into learning Git was not just about mastering a tool but embracing a mindset—the mindset of continuous improvement, collaboration, and adaptability. Git became more than just lines of code; it symbolized resilience in the face of challenges and the perseverance to overcome obstacles.\nAs I continue to traverse the ever-evolving landscape of software development, Git remains an indispensable companion—a trusted ally that empowers me to tackle complex projects with confidence. My journey with Git may have had humble beginnings, but its impact on my development journey is profound and enduring.\n","date":"10 March 2024","permalink":"/blog/git/","section":"Blog","summary":"Introduction The vast landscape of software development is governed by one tool: Git.","title":"Learning Git"},{"content":"","date":"10 March 2024","permalink":"/blog/encryption/","section":"Blog","summary":"","title":"Password Encryption Algorithms"},{"content":"A comprehensive suite of AI agents for the Pac-Man game, implementing fundamental artificial intelligence techniques from graph search to reinforcement learning. Built as part of UC Berkeley\u0026rsquo;s CS188 Introduction to Artificial Intelligence course, this project demonstrates practical applications of AI algorithms in a challenging game environment.\nThe Problem Real-world AI problems require agents that can navigate complex environments, make decisions under uncertainty, and learn from experience. While Pac-Man may seem like just a game, it presents all these challenges: path planning through mazes, adversarial ghost agents with stochastic behavior, partial observability with invisible ghosts, and the need to learn optimal strategies through trial and error.\nKey Features 🔍 Intelligent Path Finding\nImplemented four fundamental search algorithms (DFS, BFS, UCS, A*) to navigate mazes efficiently. Developed custom heuristics for A* that reduce node expansions by up to 80% while maintaining optimality. Solved complex problems like finding optimal paths to eat all food pellets using advanced state space representations.\n🎮 Multi-Agent Game Playing\nBuilt adversarial search agents using Minimax and Expectimax algorithms to play against multiple ghosts. Designed sophisticated evaluation functions that balance food collection, ghost avoidance, and winning strategies. Handles both deterministic and probabilistic ghost behaviors.\n🧠 Reinforcement Learning\nImplemented model-based (Value Iteration) and model-free (Q-Learning, Approximate Q-Learning) algorithms. Trained agents that learn optimal policies through experience, starting from zero knowledge about the game. Applied function approximation to handle large state spaces efficiently.\n👻 Probabilistic Tracking\nCreated ghost-hunting agents that track invisible ghosts using noisy distance sensors. Implemented Bayes Nets for probabilistic inference and particle filters for Hidden Markov Models. Achieved accurate ghost localization even with Manhattan distance readings corrupted by noise.\n🗺️ Logic-Based Planning\nApplied propositional logic to solve SLAM (Simultaneous Localization and Mapping) problems. Built agents that can locate themselves with unknown starting positions, map unknown environments, and plan action sequences using logical inference.\nImplementation Details Search Algorithms\nThe search module implements graph-based versions of all algorithms to avoid revisiting states. Used Python\u0026rsquo;s data structures strategically—Stack for DFS, Queue for BFS, and PriorityQueue for UCS and A*. Custom heuristics for A* use Manhattan distance for simple cases and actual maze distances for complex multi-goal problems.\nGame Playing Agents\nMinimax with alpha-beta pruning handles deterministic ghosts, searching up to depth 4 in reasonable time. Expectimax models probabilistic ghost behavior, computing expected utilities across all possible ghost actions. Evaluation functions combine weighted features: food proximity, ghost distances, power pellet opportunities, and winning conditions.\nReinforcement Learning\nValue Iteration computes optimal policies for known MDPs using dynamic programming. Q-Learning agents explore using epsilon-greedy strategies, learning state-action values through experience. Approximate Q-Learning uses feature extraction to generalize across similar states, enabling learning in large state spaces.\nProbabilistic Inference\nExact inference using the Forward Algorithm for HMMs when tracking single ghosts. Particle filtering approximates joint distributions when tracking multiple ghosts simultaneously. Dynamic particle count adjustment based on uncertainty levels improves both accuracy and performance.\nKey Algorithms Search \u0026amp; Planning:\nDFS/BFS – Complete maze exploration and shortest path finding UCS – Optimal paths with non-uniform costs A* – Optimal paths with admissible heuristics reducing search space Adversarial Search:\nMinimax – Perfect play against optimal opponents Alpha-Beta Pruning – Efficient minimax through branch elimination Expectimax – Rational decisions against stochastic opponents Learning \u0026amp; Inference:\nValue/Policy Iteration – Computing optimal policies for MDPs Q-Learning – Model-free reinforcement learning Particle Filtering – Approximate inference in continuous spaces Challenges \u0026amp; Solutions Challenge: Designing admissible heuristics for multi-goal search problems (eating all food)\nSolution: Used minimum spanning tree of remaining food as heuristic, ensuring admissibility while providing tight bounds that dramatically reduce search space\nChallenge: Balancing exploration vs exploitation in Q-Learning\nSolution: Implemented adaptive epsilon-greedy strategy that decreases exploration over time, transitioning from learning to optimal play\nChallenge: Tracking multiple invisible ghosts with noisy sensors\nSolution: Particle filter with intelligent resampling—concentrates particles in high-probability regions while maintaining diversity to avoid particle depletion\nNote: Source code available upon request as per UC Berkeley\u0026rsquo;s academic integrity policies.\nRequest Source Code\n","date":"1 May 2022","permalink":"/projects/pacmanai/","section":"Projects","summary":"A comprehensive suite of AI agents for the Pac-Man game, implementing fundamental artificial intelligence techniques from graph search to reinforcement learning.","title":"PacmanAI"},{"content":"A lightweight version control system that implements Git\u0026rsquo;s core functionality from scratch in Java. Built as part of UC Berkeley\u0026rsquo;s CS61B Data Structures course, Gitlet demonstrates practical application of data structures including trees, hash maps, and directed acyclic graphs to solve real-world problems.\nThe Problem Understanding how version control systems work under the hood is crucial for software engineers, yet most developers only interact with Git at a surface level. This project required building a functional VCS from the ground up, handling everything from object serialization to complex merge algorithms—all while maintaining efficiency and correctness.\nKey Features 📁 Complete Version Control\nImplements fundamental Git operations: init, add, commit, rm, status, log, and checkout. Each commit creates an immutable snapshot of the repository state, stored efficiently using SHA-1 hashing for content-addressable storage.\n🌳 Branching \u0026amp; Merging\nFull support for creating, switching, and deleting branches. Implements a sophisticated merge algorithm that handles split points, conflict detection, and automatic merging when possible. The commit tree structure uses directed acyclic graphs to maintain branch relationships.\n⚡ Efficient Storage\nUses blob objects for file storage with content-based deduplication—identical files share the same blob regardless of commit or filename. Implements lazy loading and caching strategies to minimize disk I/O operations.\n🔍 History Tracking\nComprehensive logging with log (current branch history) and global-log (all commits). The find command searches commit messages across the entire repository history. Status command provides detailed staging area and working directory information.\nTechnical Implementation Persistence Layer\nBuilt a custom serialization system using Java\u0026rsquo;s Serializable interface to persist repository state to disk. The .gitlet directory structure mirrors Git\u0026rsquo;s design with separate folders for commits, blobs, and branches. Each object is stored with its SHA-1 hash as the filename, enabling O(1) lookups.\nData Structures\nCommit Tree: Directed acyclic graph implementation tracking parent-child relationships Staging Area: HashMap-based structure for tracking additions and removals Blob Storage: Content-addressable storage using SHA-1 hashing for deduplication Branch Management: Reference system pointing to commit SHAs Merge Algorithm\nImplements a three-way merge that:\nFinds the split point (latest common ancestor) using BFS traversal Compares files across current branch, given branch, and split point Automatically merges non-conflicting changes Marks conflicts for manual resolution when both branches modify the same file Key Commands Repository Management:\ninit – Creates new repository with initial commit add/rm – Stages files for addition or removal commit – Creates immutable snapshot with parent reference History \u0026amp; Branches:\nlog/global-log – Views commit history branch/rm-branch – Creates or deletes branches checkout – Restores files or switches branches reset – Moves current branch to specified commit Advanced Operations:\nmerge – Three-way merge with conflict detection find – Searches commits by message status – Displays repository state Challenges \u0026amp; Solutions Challenge: Implementing efficient file deduplication across commits\nSolution: Content-based addressing using SHA-1 hashes—identical files reference the same blob object regardless of name or location\nChallenge: Finding the merge split point in complex branch histories\nSolution: BFS traversal of the commit DAG to find the latest common ancestor, handling multiple merge commits correctly\nChallenge: Managing persistence without a database\nSolution: Custom serialization layer with careful file organization, using SHA-1 hashes as natural indexes for O(1) retrieval\nNote: Source code available upon request as per UC Berkeley\u0026rsquo;s academic integrity policies.\nRequest Source Code\n","date":"1 December 2021","permalink":"/projects/gitlet/","section":"Projects","summary":"A lightweight version control system that implements Git\u0026rsquo;s core functionality from scratch in Java.","title":"Gitlet"},{"content":"I\u0026rsquo;m a software engineer passionate about building scalable systems and solving complex problems. Currently studying Computer Science at UC Berkeley with hands-on experience at major tech companies—if you\u0026rsquo;d like to collaborate or discuss opportunities, feel free to reach out via LinkedIn.\nHi, I\u0026rsquo;m Christopher 👋 📍 Location: San Francisco, CA\n💻 Focus: Full-Stack Development \u0026amp; Cloud Architecture\n🎓 University: UC Berkeley (Class of 2026) - Computer Science, 3.79 GPA\n📧 Email: leechristopher722@gmail.com\n🔗 GitHub: @leechristopher722\nMy Journey 🚀 I\u0026rsquo;m currently in my final year at UC Berkeley, where I\u0026rsquo;ve developed a strong foundation in algorithms, data structures, and system design. My academic journey has been enriched by real-world experience through competitive internships and leadership roles.\nRecent Experience:\nAmazon Web Services - Built international marketplace automation for enterprise EC2 pricing, reducing operational load by 20% and eliminating high-severity incidents OpenGrant - Engineered AI evaluation pipelines using advanced prompting techniques and created comprehensive UI/UX designs for grant proposal platforms U.S. Army (KATUSA) - Led cross-cultural teams of 50+ members, coordinating large-scale operations and serving as a linguistic liaison 📄 View Full Resume | 🛠️ Explore My Projects\nBeyond Code 🌟 When I\u0026rsquo;m not coding, you\u0026rsquo;ll find me behind the bar mixing up creative cocktails for my friends—I love experimenting with different spirits and flavors to come up with something completely new. I\u0026rsquo;m also constantly exploring San Francisco\u0026rsquo;s food scene, from hole-in-the-wall spots to trendy new restaurants, and I\u0026rsquo;m always on the mission to find the city\u0026rsquo;s most amazing coffee shops.\nWhether it\u0026rsquo;s perfecting a new cocktail recipe or discovering an amazing restaurant together, I love bringing people together over great food and drinks. These moments of connection and creativity keep me energized and inspired, both in life and in my work.\n","date":null,"permalink":"/about/","section":"Christopher Lee","summary":"I\u0026rsquo;m a software engineer passionate about building scalable systems and solving complex problems.","title":"About"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/tags/web-development/","section":"Tags","summary":"","title":"Web Development"}]