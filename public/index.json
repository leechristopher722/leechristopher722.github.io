[{"content":"","date":null,"permalink":"/tags/backend-development/","section":"Tags","summary":"","title":"Backend Development"},{"content":" My Learning Journey ","date":null,"permalink":"/blog/","section":"Blog","summary":" My Learning Journey ","title":"Blog"},{"content":" Designing and Developing Tomorrow\u0026rsquo;s Solutions Welcome to my portfolio! Discover my projects, blog, and experiences, and feel free to reach out. I\u0026rsquo;m always excited to collaborate on new challenges and opportunities!\n","date":null,"permalink":"/","section":"Christopher Lee","summary":"Designing and Developing Tomorrow\u0026rsquo;s Solutions Welcome to my portfolio!","title":"Christopher Lee"},{"content":"What is Cloud Computing? # On-Premise\nLess scalability (less flexibility) Server Storage (have to maintain and power it) Less Data Security Data Loss (data recovery can be hard) Maintenance have to be done by the company itself Less collaboration Cloud\nMore scalability (more flexibility) Server Storage (have to maintain and power it) Better Data Security Data Loss (data recovery measures are there) Maintenance More collaboration (easier to share data in diff locations) About Cloud # Delivery of on demand computing services on the internet Pay-as-you-Go (pay more, scale up / pay less, scale down) Cost efficient Deployment Model # Public Cloud Like a bus Lower cost (pay only for resources used) Owned by Cloud Providers Private Cloud Like owning a car Managed by single organization or third party Pay large amount up front (owned by the company) Hybrid Cloud Using both Like in Federal Agencies (store personal data, share nonsensitive data on public cloud) Service Model # IaaS Infrastructure Access to basic computing infrastructure Commonly used by IT Administrators Storage or VMs, Networking, Servers Pay for What You Use PaaS Platforms Platform and runtime environments provided for Dev, Testing, Managing Applications Commonly Used By Software Developers Don\u0026rsquo;t have to acquire, manage, maintain related architecture Only have to handle App and Data SaaS Software Involves hosting and managing software applications Not owning any IT equipment Commonly Used by End Customers Popular Services # AWS Services over the Internet IaaS is their main Subscriptions are pay what you use Azure Google Cloud Platform Lifecycle of Cloud Computing Solution # Understand the requirements of the business (Define purpose) Choose a compute service that will provide the right support where you resize the compute capacity in the cloud to run application programs (Define the Hardware ex. EC2, Lambda, Elastic Container Service) Define Storage - Choose storage service for backup and archive data (S3, EFS, Glacier) Define Network - securely deliver data, videos, applications, etc (VPC, Route 53, Direct Connect) Define Security - user Auth, etc. (IAM, KMS, Cognito) Define Management Processes and Tools (CloudWatch, Auto scaling, CloudFormation) Testing Process - CodeStar, CodeBuild, CodePipeline (build, test, deploy code quickly) Analytics - Athena, EMR, CloudSearch Containers # Docker, Cloud Foundary, Kubernetes, etc. ","date":"20 March 2024","permalink":"/blog/cloud/","section":"Blog","summary":"What is Cloud Computing?","title":"Cloud"},{"content":"","date":null,"permalink":"/tags/cloud-computing/","section":"Tags","summary":"","title":"Cloud Computing"},{"content":"Write about restful api here.\nAPI: Application Programming Interface. Piece of software that can be used by another piece of software, in order to allow applications to talk to each other.\nREST:\nSeparate API into logical resources users projects bugs teams Expose structured, resource-based urls *//www.myproject.com/addNewProject (not good) *//www.myproject.com/projects/8(Project ID) (use HTTP Method such as \u0026lsquo;get\u0026rsquo;) Use HTTP methods Create: Post Read: Get Update: Put / Patch (for patch, only need part of object) Delete: Delete Send data as JSON Be stateless All state is handled on the client Server should not have to remember previous requests Only use app.js for express related configs \u0026amp; more For env variables, deal with it in server.js\nEnvironment Variables\nDev Environment NODE_ENV = development Prod Environment NODE_ENV = production MongoDB\nNoSQL database Collections (tables) Documents (rows) Scalable \u0026amp; Flexible Mongoose\nObject Data Modeling(ODM) library for MongoDB and Node.js, higher level abstraction rqpid and simple development of mongoDB database interactions schemas, easy data validations, simple query api, middleware etc. schema: where we model data, describing structure, default vals, and validation Mongoose model: wrapper for the schema, pproviding an interface to the database for CRUD operations MVC # Separate Business Logic \u0026amp; Application Logic\nApplication Logic (Controller) Only concerned with application\u0026rsquo;s implementation managing req and res more of technical aspects bridge between model and view Business Logic (Model) Code tath actualy solves the business problem Directly related to business rules EX Creating new tours in database Check if user pw is correct Validating user input data Ensuring only users who bought a tour can review it Fat Models \u0026amp; Thin Controllers: offload as much logic as possible onto the model, and keep controllers as simple as possible Model\nApplications data, Business logic Controller\nHandle application requests, interact with models, send back responses to client View\nGUI, server-side rendered wbesites Alias\nCreating middleware for popular routers/requests Aggregation Pipeline\nFor grouping, sorting, filtering data to get statistics that are useful for ex business needs Mongoose Middleware:\nDocument Middleware: before or after saving documents Query Middleware: Aggregation Middleware: Model Middleware Data Sanitization \u0026amp; Validation # Setting models for each data types Errors in Express # Operational error Problems that we can predict will happen at some point Invalid user input, failed to connect to server, request timeout, invalid path accessed, etc. -\u0026gt; Create a global express handling middleware so that all operational errors end up there.\nProgramming error Bugs in code User Authentication \u0026amp; Authorization # bcrypt for password hashing =\u0026gt; Argon2 is the newest algorithm among these and is currently considered to be the strongest password hashing algorithm available. It is designed to be memory-hard, meaning that it requires a lot of memory to compute. This makes it difficult for attackers to use specialized hardware like GPUs and ASICs to crack passwords. Argon2 has several parameters that need to be kept in mind when using it, such as the amount of memory to use and the number of iterations to perform. Bcrypt is an older algorithm but is still widely used and considered to be secure. It is designed to be computationally expensive, meaning that it requires a lot of processing power to compute. Bcrypt has a cost parameter that determines the number of iterations to perform, and it also has a work factor that determines the amount of memory to use.\nScrypt is similar to bcrypt in that it is also designed to be computationally expensive. However, it is also designed to be memory-hard, like Argon2. Scrypt has several parameters that need to be kept in mind, such as the amount of memory to use and the number of iterations to perform.\nPBKDF2 is a key derivation function that is designed to be computationally expensive. It is often used in conjunction with other algorithms, such as SHA-256 or SHA-512, to create a stronger password hashing function. PBKDF2 has a number of parameters, such as the number of iterations to perform and the length of the derived key.\nWhen choosing which algorithm to use, it\u0026rsquo;s important to consider the specific requirements of your use case. Factors such as the number of users, the computing resources available, and the security requirements should all be taken into account. In general, newer algorithms like Argon2 are considered to be stronger than older ones like bcrypt and PBKDF2, but they may require more memory or processing power to compute. It\u0026rsquo;s also important to keep in mind that password hashing is just one aspect of password security, and other measures like password policies and multi-factor authentication should also be used to improve security.\nJSON WEB TOKEN WRITE HOW IT WORKS\nUser AUTH IS SERIOUS AND IMPORTANT: DO IT RIGHT\nSent email for resetting password\nSecurity Practices # Copmromised Database Encrypt passwords with salt and hash (argon2) Encrypt password reset tokens (sha256) Brute force attacks Make login requests be slow (argon2) Implement rate limiting (express-rate-limit) Implement maximum login attempts (not implemented) Cross-site scripting(XSS) attacks Store JWT in HTTP only cookies Sanitize user input data Set special HTTP headers (helmet package) Denial-of-Service (DOS) attack Implement rate limiting (express-rate-limit) Limit body payload (in body-parser) Avoid evil regular expressions NoSQL Query Injection Use mongoose for MongoDB (schemaTypes) Sanitize user input data Other practices Always use HTTPS Create random password reset token with expiry dates Deny access to JWT after password change Don\u0026rsquo;t commit sensitive config data to Git Don\u0026rsquo;t send error details to clients Prevent Cross-Site Request Forgery (csurf package) Require re-authentication before a high-value action Implement a blacklist of untrusted JWT Confirm user email address after first creating account Keep user logged in with refresh tokens Implement two-factor authentication Prevent parameter pollution causing Uncaught Exceptions Data Modeling # Different types of relationships between data\n1:1 1:Many 1:Few 1:Many 1:Ton Many:Many Referencing/normalization vs Embedding/denormalization\nReferenced Pro: Easier to query each document on its own Con: need 2 queries to get data from referenced document Embedded Pro: can get all the information in one query Con: impossible to query embedded document on its own Embedding or referencing decisions\nRelationship type Data access patterns Data closeness Different types of referencing\nChild referencing Parent referencing (Best One) Two-way referencing FACTORY FUNCTION\nWorks bc of JAVASCRIPT CLOSURES: Inner function gets access to vars of outer functions even after it is returned USE INDEXES TO IMPROVE DB READ PERFORMANCE: Consider read-write pattern, compare query of using exact field with cost of using index\nIt takes memory to use indexes. Only use on low Write-Read ratio documents (More reads than writes) TODO::Implement caching to prevent multiple requests of same data. # https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Client-side_web_APIs/Client-side_storage Cookies vs Web Storage API vs IndexedDB For better performance and/or larger datasets, IndexedDB is better However, only used for simple use cases Handlebars SUCK # Cannot directly access res.locals, but pug can Does not have extends, but only partials # TO provide current project ID into JS Frontend Code, create a hidden field in HTML/Pug with req.body.project._id included #TODO: Instead of deleting tickets \u0026amp; projects, mark them as inactive and simply don\u0026rsquo;t display it to user. #Implemented Client-Side Rendering with frontend JS for comments on Tickets to reduce initial loading time and inefficient data retrievals #To Learn\nPromise Feedback Loop function() {} vs () =\u0026gt; {} Static Method vs Review Method Choices Made # MongoDB choice: mySQL, noSQL, postgreSQL (child vs parent vs 2 way refenrencing vs embedding) How I applied MVC Security measures done (pw on DB, argon2, and more) Performance improvements Which templating engines to use (Pug, handlebars, ejs) Which frontend framework should be used? Created a middleware that stores three recently viewed projects in cookie. #","date":"20 March 2024","permalink":"/blog/api/","section":"Blog","summary":"Write about restful api here.","title":"RESTful API"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"Project management tool for developers; combines Gitlet with Dynamic Web Application to provide efficient workflow in team projects.\nComing soon\u0026hellip;\n","date":"14 March 2024","permalink":"/projects/atelier/","section":"Projects","summary":"Project management tool for developers; combines Gitlet with Dynamic Web Application to provide efficient workflow in team projects.","title":"Atelier"},{"content":"","date":null,"permalink":"/tags/machine-learning/","section":"Tags","summary":"","title":"Machine Learning"},{"content":" From ideas to reality ","date":null,"permalink":"/projects/","section":"Projects","summary":" From ideas to reality ","title":"Projects"},{"content":"The field of software development is witnessing a paradigm shift with the introduction of Devin, an AI tool claiming the title of the world\u0026rsquo;s first \u0026ldquo;AI software engineer.\u0026rdquo; This blog post delves into Devin\u0026rsquo;s technical underpinnings, analyzes its potential impact, and explores how it stands out from existing AI development tools.\nBeyond Code Completion: Unveiling Devin\u0026rsquo;s Technical Core #Devin surpasses the capabilities of typical code-completion AI. It is believed to leverage a sophisticated blend of algorithms, including:\nNatural Language Processing (NLP): This empowers Devin to comprehend high-level instructions provided in natural language and translate them into specific coding tasks. Machine Learning (ML): Devin utilizes ML models trained on vast code repositories to grasp coding patterns, identify best practices, and detect potential bugs. Deep Learning (DL): While the specifics remain undisclosed, Devin likely employs DL algorithms to analyze code structure and functionality, enabling it to tackle complex tasks like code generation, debugging, and even deployment. Performance Evaluation: A Quest for Concrete Data #A critical aspect of Devin\u0026rsquo;s development is its real-world performance. However, concrete benchmarks are currently limited. Cognition, Devin\u0026rsquo;s creator, asserts its ability to:\nGenerate entire applications based on a single prompt. Successfully complete real-world freelance projects on platforms like Upwork. Identify and rectify bugs within existing codebases. Independent testing and user evaluations are still in their infancy. It\u0026rsquo;s essential to acknowledge that Devin is likely under active development, and its true capabilities will likely unfold over time.\nA Step Ahead: How Devin Differs from Existing Tools #While AI development tools like Github Copilot and ChatGPT have revolutionized code completion and assisted development, Devin offers a distinct advantage: end-to-end project management.\nHere\u0026rsquo;s how Devin breaks new ground:\nFull Development Lifecycle Management: Unlike assistants that focus on code snippets, Devin tackles the entire development lifecycle, from translating high-level ideas into code to debugging and deployment. Independent Problem-Solving: Devin reportedly possesses impressive planning abilities. It can anticipate potential challenges and structure the development process accordingly, minimizing human intervention. Constant Learning: Devin is said to continuously learn and improve from its experiences. This ongoing development cycle allows it to stay up-to-date with programming best practices and adapt to new technologies. Collaboration, Not Competition: Reshaping the Programmer-AI Dynamic #While Devin\u0026rsquo;s code generation and project management skills are impressive, it\u0026rsquo;s crucial to view it as a collaborative tool, not a competitor. Here\u0026rsquo;s how Devin can truly empower programmers:\nEnhanced Efficiency: Repetitive coding tasks can be delegated to Devin, allowing programmers to focus on strategic planning and creative problem-solving. Error Reduction: Devin\u0026rsquo;s bug-detection capabilities can significantly improve code quality and expedite debugging processes. Exploration of New Technologies: Devin\u0026rsquo;s continuous learning can aid programmers in staying ahead of the curve by facilitating the exploration and integration of new technologies into their projects. The Future: Embracing an AI-Powered Development Landscape #Devin\u0026rsquo;s arrival signifies that AI is not here to replace programmers, but rather to augment their capabilities. By embracing AI-powered tools like Devin, we can usher in a future of software development characterized by greater efficiency and groundbreaking innovation.\nThis is merely the beginning. As Devin and similar AI tools evolve, the way we approach software development will undoubtedly transform. It\u0026rsquo;s important to remain curious, experiment with these new tools, and prepare to co-create the future alongside our AI teammates.\n","date":"14 March 2024","permalink":"/blog/devin/","section":"Blog","summary":"The field of software development is witnessing a paradigm shift with the introduction of Devin, an AI tool claiming the title of the world\u0026rsquo;s first \u0026ldquo;AI software engineer.","title":"Thoughts on Devin: AI Software Engineer"},{"content":"In the realm of web development, crafting an online portfolio can often feel like a daunting task. As developers, we aim to showcase our skills and projects in an efficient, visually appealing manner. However, the process can become overwhelming without the right tools at our disposal. This is where Hugo and GitHub Pages come into play, offering a seamless solution for building and hosting dynamic portfolios. Let\u0026rsquo;s delve deeper into why this combination is a game-changer for developers.\nWhat is Hugo?\nHugo is a static site generator designed to simplify website development. Unlike traditional content management systems (CMS), such as WordPress or Drupal, Hugo generates static HTML files that can be served directly to the user\u0026rsquo;s browser. This means there\u0026rsquo;s no need for complex databases or server-side processing, resulting in a leaner, more efficient website.\nWhy is Hugo Fast?\nHugo\u0026rsquo;s speed is unparalleled, thanks to its architecture. It is built with Go, a programming language known for its speed and efficiency. Additionally, Hugo employs a clever caching mechanism that allows it to regenerate only the necessary files when changes are made, drastically reducing build times.\nIntroducing GitHub Pages:\nGitHub Pages is a static site hosting service offered by GitHub. It allows users to host their websites directly from their GitHub repositories. With GitHub Pages, developers can easily deploy their Hugo-generated sites with just a few clicks, taking advantage of GitHub\u0026rsquo;s robust infrastructure and version control capabilities.\nStrengths of Hugo and GitHub Pages:\nSimplicity: Both Hugo and GitHub Pages prioritize simplicity, making them accessible to developers of all skill levels. Hugo\u0026rsquo;s intuitive templating system and GitHub Pages\u0026rsquo; seamless deployment process streamline the entire development workflow. Customization: Despite their simplicity, Hugo and GitHub Pages offer ample opportunities for customization. Hugo provides a wide range of themes and customization options, allowing developers to tailor their portfolios to their unique style and preferences. GitHub Pages, on the other hand, supports custom domains and SSL certificates, enabling developers to create a professional online presence. Performance: The combination of Hugo and GitHub Pages results in lightning-fast websites. Since Hugo generates static HTML files, there\u0026rsquo;s no need for server-side processing, leading to near-instantaneous page loads. Additionally, GitHub Pages\u0026rsquo; global CDN ensures that content is delivered quickly to users around the world. Comparing Static Website Building Tools:\nWhile Hugo is undoubtedly a powerful static site generator, it\u0026rsquo;s essential to explore other options to determine the best fit for your project. Some popular alternatives include Jekyll, Gatsby, and Next.js. Each tool has its strengths and weaknesses, depending on factors such as performance requirements, ease of use, and community support.\nJekyll, for example, is well-suited for simple websites and blogs, thanks to its seamless integration with GitHub Pages. Gatsby, on the other hand, is ideal for more complex projects that require dynamic data fetching and server-side rendering. Next.js shines in the realm of React-based applications, offering advanced features like incremental static regeneration and hybrid rendering.\nIn conclusion, building an online portfolio doesn\u0026rsquo;t have to be a daunting task. With the powerful combination of Hugo and GitHub Pages, developers can create sleek, high-performance websites with ease. Whether you\u0026rsquo;re a seasoned developer or just starting, Hugo and GitHub Pages provide the perfect platform to showcase your skills and projects to the world.\nVisit the Hugo website!\n","date":"13 March 2024","permalink":"/blog/hugo/","section":"Blog","summary":"In the realm of web development, crafting an online portfolio can often feel like a daunting task.","title":"Building Static Website with HUGO"},{"content":"","date":null,"permalink":"/tags/hugo/","section":"Tags","summary":"","title":"Hugo"},{"content":"","date":null,"permalink":"/tags/cybersecurity/","section":"Tags","summary":"","title":"CyberSecurity"},{"content":"","date":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git"},{"content":"Introduction #The vast landscape of software development is governed by one tool: Git. It\u0026rsquo;s the backbone of collaboration, enabling developers to work seamlessly together, track changes efficiently, and maintain a coherent history of their projects. However, like many budding developers, my journey into understanding Git was initially daunting and filled with uncertainty. Yet, as I delved deeper into its intricacies, I discovered its immense value and transformed my workflow.\nUnderstanding the Basics #My foray into Git began with a simple desire—to streamline my coding projects and collaborate more effectively with my peers. As a novice developer, the prospect of learning a new tool seemed daunting. Git\u0026rsquo;s command-line interface appeared cryptic, and the plethora of commands felt overwhelming. However, armed with determination and a willingness to learn, I embarked on my journey.\nMy initial steps involved grasping the fundamental concepts of Git. Understanding terms like repositories, commits, branches, and merges laid the groundwork for my comprehension. I devoured online tutorials, perused documentation, and sought guidance from experienced developers. Slowly but surely, the fog began to lift, and I started to appreciate Git\u0026rsquo;s elegance.\nExploring Branches #One of the pivotal moments in my Git journey was comprehending the concept of branches. Branching allowed me to diverge from the main codebase, experiment with new features, and isolate changes without disrupting the main project. It was akin to creating alternate realities where I could test ideas freely, knowing that I could always revert if needed. This newfound freedom unleashed my creativity and empowered me to explore different avenues in my projects.\nVisual representation of branching in Git\nAdvanced Functionalitie #As I grew more proficient, I ventured into more advanced Git functionalities. Rebasing, squashing commits, and resolving merge conflicts were once intimidating concepts that now became integral parts of my workflow. Git became not just a version control system but a powerful toolkit that enabled me to manage my projects with finesse.\n# Example of rebasing in Git git checkout feature-branch git rebase main Overcoming Challenges #However, like any journey of learning, I encountered roadblocks along the way. Git\u0026rsquo;s unforgiving nature meant that a single misstep could wreak havoc on my project. Accidentally deleting files, botching merges, or losing track of changes were all too familiar pitfalls. Yet, with each mistake, I gleaned valuable lessons and honed my skills further.\nCollaborative Workflows #Moreover, Git\u0026rsquo;s collaborative nature became increasingly apparent as I worked on group projects. Branches transformed into collaborative spaces where team members could contribute code, review each other\u0026rsquo;s work, and seamlessly integrate changes. Pull requests became the cornerstone of our workflow, facilitating code reviews and ensuring the quality of our codebase.\nVisual representation of a collaborative Git workflow\nGit in the Industry #Perhaps the most profound realization during my Git journey was its ubiquity within the software development industry. Virtually every tech company, from startups to tech giants, relies on Git for version control. Mastery of Git not only enhanced my individual capabilities but also opened doors to collaboration and employment opportunities within the industry.\nConclusion #In hindsight, my journey into learning Git was not just about mastering a tool but embracing a mindset—the mindset of continuous improvement, collaboration, and adaptability. Git became more than just lines of code; it symbolized resilience in the face of challenges and the perseverance to overcome obstacles.\nAs I continue to traverse the ever-evolving landscape of software development, Git remains an indispensable companion—a trusted ally that empowers me to tackle complex projects with confidence. My journey with Git may have had humble beginnings, but its impact on my development journey is profound and enduring.\n","date":"10 March 2024","permalink":"/blog/git/","section":"Blog","summary":"Introduction #The vast landscape of software development is governed by one tool: Git.","title":"Learning Git"},{"content":"","date":"10 March 2024","permalink":"/blog/encryption/","section":"Blog","summary":"","title":"Password Encryption Algorithms"},{"content":"A series of AI engines for the PacMan game, utilizing multiagent search algorithms, reinforcement learning, and more.\nThis project consists of 4 parts:\nSingle/Multiagent Search Logic Bayes Nets and HMMs Reinforcement Learning Single/Multiagent Search #Depth-first, breadth-first, uniform cost, and A* search. Minimax and expectimax algorithms along with designing evaluation functions for multi-agent search.\nConditions \u0026amp; Algorithms Used: Locating Fixed Food: Depth First, Breath First, A*, Suboptimal Search Logic #Applying Propositional Logic in a pacman world represented with booleans to solve planning tasks as well as localization, mapping, and SLAM.\nGoals:\nCreate logical expressions that represent Pacman physics and locate Pacman agent\u0026rsquo;s position given its actions and sensor readings. Plan sequence of actions to the goal position. Plan sequence of actions to eat all the food on the board. Locate Pacman agent\u0026rsquo;s position at each timestep with known map, unknown starting position, and sensors. Map the entire board with known starting location and sensors. Locate Pacman agent\u0026rsquo;s position and Map the entire board with unknown map, unknown starting position, and sensors (Simultaneous Localization and Mapping). Results:\nBayes Nets and HMMs #Bayes Nets and the forward algorithm, employing particle sampling in Hidden Markov Models to locate ghosts based on noisy distance readings.\nGoal: Locate and eat invisible ghosts with sensors that provide nosiy readings of the Manhattan distance.\nResult:\nReinforcement Learning #Value Function, Q learning, and Approximate Q learning to teach Pacman and crawler agents rational policies.\nWhat I\u0026rsquo;ve Learned # Algorithm Implementation: Through Projects 1 and 2, I gained proficiency in implementing search algorithms and understanding their effectiveness in solving navigation and adversarial problems. This involved grasping concepts like depth-first, breadth-first, uniform cost, A* search, multiagent minimax, and expectimax algorithms.\nReinforcement Learning: Project 3 introduced me to reinforcement learning techniques such as Value Function, Q learning, and Approximate Q learning. By implementing these algorithms, I learned how agents can learn optimal policies through trial and error, improving decision-making in dynamic environments.\nProbabilistic Inference: Project 4 deepened my understanding of probabilistic reasoning by employing Bayes Nets and Hidden Markov Models (HMMs). I learned how to use inference algorithms like the forward algorithm and particle sampling to make probabilistic predictions, crucial for tasks like ghost tracking in Pacman.\nProblem Solving and Critical Thinking: Across all projects, I honed my problem-solving skills and developed a critical mindset towards algorithm selection and implementation. I learned to evaluate the trade-offs between different approaches and make informed decisions based on the specific requirements of each problem.\nOverall, working on these projects equipped me with practical skills in AI and machine learning, fostering a deeper understanding of their applications in gaming and beyond. Additionally, it instilled in me a sense of confidence in tackling complex problems and leveraging advanced techniques to find effective solutions.\nDisclaimer\nThis project was developed for UC Berkeley\u0026rsquo;s CS188: Introduction to Artificial Intelligence Course. Source code can be provided on request.\n","date":"1 May 2022","permalink":"/projects/pacmanai/","section":"Projects","summary":"A series of AI engines for the PacMan game, utilizing multiagent search algorithms, reinforcement learning, and more.","title":"PacmanAI"},{"content":"A version-control system similar to Git but designed to be simpler and smaller.\nKey functionalities:\nSaving file versions (committing): Creates snapshots of entire directories, enabling restoration to previous states. Restoring file versions (checking out): Reverts files or entire commits to a chosen point in time. Viewing history (log): Displays a chronological list of commits made to the project. Maintaining branches: Creates divergent development paths within the project. Merging branches: Combines changes from different branches into a single branch. Differences from actual Git # Flat Directory Structure: Gitlet incorporates trees into commits but does not deal with subdirectories. This results in a \u0026ldquo;flat\u0026rdquo; directory structure where each repository contains only plain files without nested directories.\nLimited Merging: Unlike Git, which supports merges with any number of parents, Gitlet limits merges to references with only two parents.\nMinimal Metadata: Gitlet\u0026rsquo;s metadata for commits is simplified, consisting only of a timestamp and a log message. A commit in Gitlet includes a log message, timestamp, a mapping of file names to blob references, and (for merges) a second parent reference.\nDetailed functionalities: #Commands:\ninit: Creates a new Gitlet repository in the current directory. add: Stages a file for inclusion in the next commit. commit: Creates a new commit with the staged changes and a commit message. rm: Removes a file from the staging area and marks it for untracking in the next commit. log: Displays the commit history, starting from the current head commit and following the parent commit links. global-log: Shows information about all commits ever made, regardless of the current branch. find: Prints the unique identifiers of commits containing a specific message. status: Displays information about the current branch, staged files, removed files, modified files, and untracked files. Things I\u0026rsquo;ve Learned #Creating Gitlet deepened my grasp of version control systems and Object-Oriented Programming (OOP). Building a simplified Git taught me Java programming intricacies and reinforced my understanding of commits, branches, and merges.\nDeveloping Gitlet honed my skills in modular software design, efficient file handling, and managing complex data structures. It prompted critical thinking about design trade-offs, emphasizing simplicity without sacrificing functionality.\nIn summary, Gitlet enhanced my technical proficiency and appreciation for version control and software design principles, showcasing the value of hands-on learning in software engineering.\nDisclaimer\nThis project was developed for UC Berkeley\u0026rsquo;s CS61B: Data Structures Course. Source code can be provided on request.\n","date":"1 December 2021","permalink":"/projects/gitlet/","section":"Projects","summary":"A version-control system similar to Git but designed to be simpler and smaller.","title":"Gitlet"},{"content":"I\u0026rsquo;m a software engineer passionate about building scalable systems and solving complex problems. Currently studying Computer Science at UC Berkeley with hands-on experience at major tech companies—if you\u0026rsquo;d like to collaborate or discuss opportunities, feel free to reach out via LinkedIn.\nHi, I\u0026rsquo;m Christopher 👋 #📍 Location: San Francisco, CA\n💻 Focus: Full-Stack Development \u0026amp; Cloud Architecture\n🎓 University: UC Berkeley (Class of 2026) - Computer Science, 3.79 GPA\n📧 Email: leechristopher722@gmail.com\n🔗 GitHub: @leechristopher722\nMy Journey 🚀 #I\u0026rsquo;m currently in my final year at UC Berkeley, where I\u0026rsquo;ve developed a strong foundation in algorithms, data structures, and system design. My academic journey has been enriched by real-world experience through competitive internships and leadership roles.\nRecent Experience:\nAmazon Web Services - Built international marketplace automation for enterprise EC2 pricing, reducing operational load by 20% and eliminating high-severity incidents OpenGrant - Engineered AI evaluation pipelines using advanced prompting techniques and created comprehensive UI/UX designs for grant proposal platforms U.S. Army (KATUSA) - Led cross-cultural teams of 50+ members, coordinating large-scale operations and serving as a linguistic liaison 📄 View Full Resume | 🛠️ Explore My Projects\nBeyond Code 🌟 #When I\u0026rsquo;m not coding, you\u0026rsquo;ll find me behind the bar mixing up creative cocktails for my friends—I love experimenting with different spirits and flavors to come up with something completely new. I\u0026rsquo;m also constantly exploring San Francisco\u0026rsquo;s food scene, from hole-in-the-wall spots to trendy new restaurants, and I\u0026rsquo;m always on the mission to find the city\u0026rsquo;s most amazing coffee shops.\nWhether it\u0026rsquo;s perfecting a new cocktail recipe or discovering an amazing restaurant together, I love bringing people together over great food and drinks. These moments of connection and creativity keep me energized and inspired, both in life and in my work.\n","date":null,"permalink":"/about/","section":"Christopher Lee","summary":"I\u0026rsquo;m a software engineer passionate about building scalable systems and solving complex problems.","title":"About"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"}]